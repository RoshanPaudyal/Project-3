{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries that will be used in this code - pandas for data manipulation, numpy for numerical calculations, and seaborn for data visualization. The collections library is also imported to use the Counter function.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv(\"Resources/online_shoppers_intention.csv\")\n",
    "df = data.copy()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display top 5 rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of true (customer ended shopping) and false (customer ended not shopping) revenue (Bar Chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['Revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = 'Month', 'VisitorType', 'Weekend', 'Revenue'\n",
    "\n",
    "# Create an instance of the OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    encoder.fit(df[[col]])\n",
    "    df[col] = encoder.transform(df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X_data = df.drop('Revenue', axis=1)\n",
    "y_data = df['Revenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=150)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of column labels from the integer indices\n",
    "labels = X.columns\n",
    "\n",
    "# sort the feature importances and the column labels\n",
    "sort = rf.feature_importances_.argsort()\n",
    "labels_sorted = labels[sort][-10:]  # select the top 10 features based on their importances\n",
    "\n",
    "# plot the feature importances with the column labels\n",
    "plt.barh(labels_sorted, rf.feature_importances_[sort][-10:])\n",
    "plt.xlabel(\"Feature Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 10 features using the sort variable\n",
    "top10_features = X_data.columns[sort][-10:]\n",
    "\n",
    "# create a new DataFrame with only the top 10 features\n",
    "X_top10 = X_data[top10_features]\n",
    "\n",
    "X_top10.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model with All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of true (customer ended shopping) and false (customer ended not shopping) revenue (Bar Chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(df['Revenue'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â€¢\tDistribution of revenue over months.\n",
    "The resulting bar plot shows the distribution of revenue over the months. The x-axis represents the months, and the y-axis represents the count of instances for each month. The bars are color-coded to show the revenue column's value, with blue representing False (no revenue) and orange representing True (revenue). The plot provides an easy-to-read visualization of the distribution of revenue over the months, allowing for easy comparison between the different months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "revenue_df = df.sort_values('Month')\n",
    "\n",
    "# Set the style of the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a barplot of the revenue distribution over months\n",
    "sns.countplot(x=\"Month\", hue=\"Revenue\", data=df)\n",
    "\n",
    "# Add labels to the plot\n",
    "plt.title(\"Distribution of Revenue over Months\")\n",
    "plt.xlabel(\"Month\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of revenue over traffic type.\n",
    "In this case, we are using the mean revenue for each traffic type because the traffic types are represented as numerical values without any meaningful labels.\n",
    "\n",
    "If we had meaningful labels for the traffic types, we could use a count plot to show the number of occurrences of each traffic type for each revenue value (i.e., True or False). However, since we don't have labels for the traffic types, we can't use a count plot in this case. Instead, we can use the mean revenue for each traffic type as a proxy for the revenue generated by each traffic type.\n",
    "\n",
    "For example, if we have 100 instances of traffic type 1 with a revenue value of True and 50 instances of traffic type 1 with a revenue value of False, the mean revenue for traffic type 1 would be (100 * 1 + 50 * 0) / (100 + 50) = 0.67. This mean value represents the average revenue generated by traffic type 1. We can then compare this mean revenue value to the mean revenue values for other traffic types to gain insight into which traffic types generate the most revenue on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=\"TrafficType\", y=\"Revenue\", data=df)\n",
    "plt.title(\"Mean Revenue by Traffic Type\")\n",
    "plt.xlabel(\"Traffic Type\")\n",
    "plt.ylabel(\"Mean Revenue\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of revenue over special day.\n",
    "The code below uses the seaborn library to create a swarm plot of the distribution of revenue over the \"SpecialDay\" feature.\n",
    "\n",
    "A swarm plot is a type of categorical scatter plot that displays the distribution of data points for each category along an axis. In this case, the \"SpecialDay\" values are shown along the x-axis, and the revenue values are shown along the y-axis. Each point on the plot represents a single data point from the dataset, with its location on the x-axis corresponding to its \"SpecialDay\" value and its location on the y-axis corresponding to its revenue value (0 or 1).\n",
    "\n",
    "By using different colors for the revenue values, we can easily see how the distribution of revenue changes for each \"SpecialDay\" value. In this plot, orange points represent revenue=1, while blue points represent revenue=0.\n",
    "\n",
    "The plot provides useful information about the relationship between the \"SpecialDay\" feature and the revenue outcome. For example, we can see that on special days (SpecialDay values of 0.4, 0.6, and 0.8), there are fewer instances of revenue=1 than on non-special days (SpecialDay values of 0.0 and 1.0). This could suggest that customers are less likely to make purchases on special days, or that the website is less effective at converting visitors into customers on these days. However, it's important to keep in mind that this plot only shows correlation, and not causation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style of the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Create a histogram of the revenue distribution over SpecialDay\n",
    "sns.histplot(x=\"SpecialDay\", hue=\"Revenue\", data=df, multiple=\"stack\")\n",
    "\n",
    "# Add labels to the plot\n",
    "plt.title(\"Distribution of Revenue over SpecialDay\")\n",
    "plt.xlabel(\"SpecialDay\")\n",
    "plt.ylabel(\"Count\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "# Helper function to summarize\n",
    "def summarize_classification(y_test,y_pred):\n",
    "    \"\"\"\n",
    "    As it's take the actual target labels of the test set and predicted label.\n",
    "    and will Give the summary of the Goodness of fit of the mode on the Validation/test dataset.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_test,y_pred,normalize=True)\n",
    "    num_acc = accuracy_score(y_test,y_pred,normalize=False)\n",
    "    \n",
    "    prec = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1_score =  f1_score(y_test,y_pred)\n",
    "    auc_score = roc_auc_score(y_test,y_pred)\n",
    "    \n",
    "    \n",
    "    return{'Accuracy:': acc,\n",
    "           'Accuracy_count:': num_acc,\n",
    "           'Precision:': prec,\n",
    "           'Recall:': recall,\n",
    "           'F1_score:':F1_score,\n",
    "           'AUC_ROC:':auc_score}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to Build Model\n",
    "def build_model(classifier_fn,\n",
    "                name_of_y_col,\n",
    "                name_of_x_cols,\n",
    "                dataset,test_frac=0.2,\n",
    "                show_plot_auc=None):\n",
    "  \n",
    "    \"\"\"\n",
    "    Builds end to end model and share the model summary.\n",
    "    if show_plot_auc==True : Plot the AUC - ROC curve.\n",
    "    \"\"\" \n",
    "    \n",
    "    # Separating the  input features (X) and target variable (y)\n",
    "    X = df.drop('Revenue', axis=1)\n",
    "    y = df['Revenue']\n",
    "    \n",
    "    # feature Scaling\n",
    "    scale_x = StandardScaler()\n",
    "    x = scale_x.fit_transform(X)\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "    \n",
    "    model = classifier_fn(x_train,y_train)\n",
    "    \n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    y_pred_train = model.predict(x_train)\n",
    "    \n",
    "    train_summary = summarize_classification(y_train,y_pred_train)\n",
    "    test_summary = summarize_classification(y_test,y_pred)\n",
    "    \n",
    "    pred_result = pd.DataFrame({'y_test':y_test,'y_pred':y_pred})\n",
    "    \n",
    "    model_crosstab = pd.crosstab(pred_result.y_pred,pred_result.y_test)\n",
    "    \n",
    "    return{'training':train_summary,\n",
    "          'test':test_summary,\n",
    "          'confusion_matrix':model_crosstab\n",
    "          }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compare the score of different Model.    \n",
    "def compare_result():\n",
    "    \"\"\"\n",
    "    Shows Train the Test data summary for the all the Model runned in form of data dictionary.\n",
    "    \"\"\"\n",
    "    for key in result_dict:\n",
    "        print('Classification: ',key)\n",
    "        \n",
    "        print()\n",
    "        print('Training data:-')\n",
    "        for score in result_dict[key]['training']:\n",
    "            print(score,result_dict[key]['training'][score])\n",
    "            \n",
    "        print()\n",
    "        print('Test Data:-')\n",
    "        for score in result_dict[key]['test']:\n",
    "            print(score,result_dict[key]['test'][score])\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_fn(X_train, y_train, input_dim=10, output_dim=1):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(output_dim, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train,\n",
    "              epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Revenue ~ DNN'] = build_model(\n",
    "    dnn_fn, y, X, df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Unsupervised Learning - K-Nearest Neighbours (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_fn(X_train,y_train,n_neighbors=9,random_state=12) -> KNeighborsClassifier:\n",
    "    \"\"\"\n",
    "    Function to buld KNN Model for the given dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Revenue ~ KNN'] = \\\n",
    "    build_model(knn_fn,y,X,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "y_pred = result_dict['Revenue ~ KNN']['test']['y_pred']\n",
    "y_true = result_dict['Revenue ~ KNN']['test']['y_true']\n",
    "print(classification_report((y_true, y_pred)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Supervised Learning - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_fn(x_train,y_train) -> RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    Function to buld ensemble model using 50 decision trees for the given dataset\n",
    "    \"\"\"\n",
    "    # create a random forest classifier model\n",
    "    model = RandomForestClassifier(n_estimators= 50, max_depth = 15,random_state=12 )\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(x_train,y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Revenue ~ Random_Forest'] = \\\n",
    "    build_model(random_forest_fn,y,X,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
