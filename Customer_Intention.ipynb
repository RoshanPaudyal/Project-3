{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries that will be used in this code - pandas for data manipulation, numpy for numerical calculations, and seaborn for data visualization. The collections library is also imported to use the Counter function.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "data = pd.read_csv(\"Resources/online_shoppers_intention.csv\")\n",
    "df = data.copy()\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display top 5 rows of the dataset\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numeric_columns = 'Month', 'VisitorType', 'Weekend', 'Revenue'\n",
    "\n",
    "# Create an instance of the OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "for col in non_numeric_columns:\n",
    "    encoder.fit(df[[col]])\n",
    "    df[col] = encoder.transform(df[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train and test sets\n",
    "X = df.drop('Revenue', axis=1)\n",
    "y = df['Revenue']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=150)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of column labels from the integer indices\n",
    "labels = X.columns\n",
    "\n",
    "# sort the feature importances and the column labels\n",
    "sort = rf.feature_importances_.argsort()\n",
    "labels_sorted = labels[sort][-10:]  # select the top 10 features based on their importances\n",
    "\n",
    "# plot the feature importances with the column labels\n",
    "plt.barh(labels_sorted, rf.feature_importances_[sort][-10:])\n",
    "plt.xlabel(\"Feature Importance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the top 10 features using the sort variable\n",
    "top10_features = X.columns[sort][-10:]\n",
    "\n",
    "# create a new DataFrame with only the top 10 features\n",
    "X_top10 = X[top10_features]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Model with All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,X_test.shape)\n",
    "print(y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of true (customer ended shopping) and false (customer ended not shopping) revenue (Bar Chart)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.countplot(df['Revenue'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### â€¢\tDistribution of revenue over months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "revenue_df = df.sort_values('Month')\n",
    "\n",
    "pd.crosstab(revenue_df['Month'],revenue_df['Revenue']).plot(kind='line',figsize=(9,8),title=\"Distribution of Revenue(Target Variable) over Months\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of revenue over traffic type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['TrafficType'],df['Revenue']).plot(kind='line',figsize=(9,8),title=\"Distribution of Revenue over TrafficType\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of revenue over special day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df['SpecialDay'],df['Revenue']).plot(kind='line',figsize=(9,8),title=\"Distribution of Revenue over SpecialDay\")\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "# Helper function to summarize\n",
    "def summarize_classification(y_test,y_pred):\n",
    "    \"\"\"\n",
    "    As it's take the actual target labels of the test set and predicted label.\n",
    "    and will Give the summary of the Goodness of fit of the mode on the Validation/test dataset.\n",
    "    \"\"\"\n",
    "    acc = accuracy_score(y_test,y_pred,normalize=True)\n",
    "    num_acc = accuracy_score(y_test,y_pred,normalize=False)\n",
    "    \n",
    "    prec = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    F1_score =  f1_score(y_test,y_pred)\n",
    "    auc_score = roc_auc_score(y_test,y_pred)\n",
    "    \n",
    "    \n",
    "    return{'Accuracy:': acc,\n",
    "           'Accuracy_count:': num_acc,\n",
    "           'Precision:': prec,\n",
    "           'Recall:': recall,\n",
    "           'F1_score:':F1_score,\n",
    "           'AUC_ROC:':auc_score}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Helper function to Build Model\n",
    "def build_model(classifier_fn,\n",
    "                name_of_y_col,\n",
    "                name_of_x_cols,\n",
    "                dataset,test_frac=0.2,\n",
    "                show_plot_auc=None):\n",
    "  \n",
    "    \"\"\"\n",
    "    Builds end to end model and share the model summary.\n",
    "    if show_plot_auc==True : Plot the AUC - ROC curve.\n",
    "    \"\"\" \n",
    "    # select the top 10 features using the sort variable\n",
    "    sort = X_top10.abs().sum(axis=1).sort_values(ascending=False).index\n",
    "    top10_features = X.columns[sort][-10:]\n",
    "\n",
    "    # create a new DataFrame with only the top 10 features\n",
    "    X = X[top10_features]\n",
    "\n",
    "    # Split your data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_top10, y, test_size=test_frac, random_state=0)\n",
    "\n",
    "    # Apply under-sampling to the training data only\n",
    "    undersampler = RandomUnderSampler(random_state=0)\n",
    "    X_train_resampled, y_train_resampled = undersampler.fit_resample(\n",
    "        X_train, y_train)\n",
    "\n",
    "    # scale numeric features using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_resampled)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "    model = classifier_fn(X_train_scaled, y_train_resampled)\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    y_pred_train = model.predict(X_train_scaled)\n",
    "    \n",
    "    train_summary = summarize_classification(X_train_scaled, y_pred_train)\n",
    "    test_summary = summarize_classification(y_test,y_pred)\n",
    "    \n",
    "    pred_result = pd.DataFrame({'y_test':y_test,'y_pred':y_pred})\n",
    "    \n",
    "    model_crosstab = pd.crosstab(pred_result.y_pred,pred_result.y_test)\n",
    "    \n",
    "    if show_plot_auc==True:\n",
    "        plt.figure(figsize=(8,6))\n",
    "        \n",
    "        logit_roc_auc1 = roc_auc_score(y_train, model.predict(x_train))\n",
    "        fpr1, tpr1, thresholds1 = roc_curve(y_train, model.predict_proba(x_train)[:,1])\n",
    "        plt.plot(fpr1, tpr1, label='Class_Train (AUC = %0.2f)' % logit_roc_auc1)\n",
    "            \n",
    "        logit_roc_auc2 = roc_auc_score(y_test, model.predict(x_test))\n",
    "        fpr2, tpr2, thresholds2 = roc_curve(y_test, model.predict_proba(x_test)[:,1])\n",
    "        plt.plot(fpr2, tpr2,label='Class_Test (AUC = %0.2f)' % logit_roc_auc2)\n",
    "        plt.plot([0, 1], [0, 1],'r--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Receiver operating characteristic(ROC-AUC)')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    return{'training':train_summary,\n",
    "          'test':test_summary,\n",
    "          'confusion_matrix':model_crosstab\n",
    "          }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to compare the score of different Model.    \n",
    "def compare_result():\n",
    "    \"\"\"\n",
    "    Shows Train the Test data summary for the all the Model runned in form of data dictionary.\n",
    "    \"\"\"\n",
    "    for key in result_dict:\n",
    "        print('Classification: ',key)\n",
    "        \n",
    "        print()\n",
    "        print('Training data:-')\n",
    "        for score in result_dict[key]['training']:\n",
    "            print(score,result_dict[key]['training'][score])\n",
    "            \n",
    "        print()\n",
    "        print('Test Data:-')\n",
    "        for score in result_dict[key]['test']:\n",
    "            print(score,result_dict[key]['test'][score])\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_fn(X_train_scaled, y_train_scaled, input_dim=17, output_dim=1) -> Sequential:\n",
    "    \"\"\"\n",
    "    Returns a deep neural network model for regression.\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=32, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units=output_dim, activation='linear'))\n",
    "\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train_scaled, y_train_scaled, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Revenue ~ DNN'] = build_model(\n",
    "    dnn_fn, name_of_y_col=y, name_of_x_cols=X, dataset=df, test_frac=0.2, show_plot_auc=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Unsupervised Learning - K-Nearest Neighbours (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_fn(X_train_scaled,y_train_scaled,n_neighbors=9,random_state=12) -> KNeighborsClassifier:\n",
    "    \"\"\"\n",
    "    Function to buld KNN Model for the given dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    model.fit(X_train_scaled,y_train_scaled)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Revenue ~ KNN'] = \\\n",
    "    build_model(knn_fn,y,X_top10,df,show_plot_auc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = result_dict['Revenue ~ KNN']['test']['y_pred']\n",
    "y_true = result_dict['Revenue ~ KNN']['test']['y_true']\n",
    "print(classification_report(y_true, y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Supervised Learning - Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_fn(x_train,y_train) -> RandomForestClassifier:\n",
    "    \"\"\"\n",
    "    Function to buld ensemble model using 50 decision trees for the given dataset\n",
    "    \"\"\"\n",
    "    # create a random forest classifier model\n",
    "    model = RandomForestClassifier(n_estimators= 50, max_depth = 15,random_state=12 )\n",
    "\n",
    "    # fit the model to the training data\n",
    "    model.fit(x_train,y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Revenue ~ Random_Forest'] = \\\n",
    "    build_model(random_forest_fn,y,X,df,show_plot_auc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compare_result())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
